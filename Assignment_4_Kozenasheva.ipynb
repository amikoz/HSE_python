{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Named entity recognition\n",
    "\n",
    "Построить модель для обнаружения и классификации именованных сущностей (named entities). На базе корпуса CoNLL 2002.  \n",
    "\n",
    "Используйте в своем решении ансамбли над решающими деревьями: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost) \n",
    "Tutorials:  \n",
    "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
    "1. https://github.com/catboost/tutorials \n",
    "\n",
    "\n",
    "Чем больше baseline'ов вы превзойдете, тем выше ваша оценка\n",
    "Метрика качества f1 (f1_macro) (чем выше, тем лучше)\n",
    " \n",
    "baseline 1: 0.0604      random labels  \n",
    "baseline 2: 0.3966      PoS features + logistic regression  \n",
    "baseline 3: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
    "\n",
    "! Your results must be reproducible. Если ваша модель - стохастическая, то вы явно должны задавать все seed и random_state в параметрах моделей   \n",
    "\n",
    "bonus, think about:  \n",
    "1. How can you exploit that words belong to some sentence?\n",
    "2. Why we selected f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "#import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SEED=1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  next-next-pos next-next-word next-pos      next-word  pos    prev-pos  \\\n",
       "0           NNS  demonstrators       IN             of  NNS  __START1__   \n",
       "1           VBP           have      NNS  demonstrators   IN         NNS   \n",
       "2           VBN        marched      VBP           have  NNS          IN   \n",
       "3            IN        through      VBN        marched  VBP         NNS   \n",
       "4           NNP         London       IN        through  VBN         VBP   \n",
       "\n",
       "  prev-prev-pos prev-prev-word      prev-word  sentence_idx           word tag  \n",
       "0    __START2__     __START2__     __START1__           1.0      Thousands   O  \n",
       "1    __START1__     __START1__      Thousands           1.0             of   O  \n",
       "2           NNS      Thousands             of           1.0  demonstrators   O  \n",
       "3            IN             of  demonstrators           1.0           have   O  \n",
       "4           NNS  demonstrators           have           1.0        marched   O  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/ner_short.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sentences\n",
    "df.sentence_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.852828\n",
       "B-geo    0.027604\n",
       "B-gpe    0.020935\n",
       "B-org    0.020247\n",
       "I-per    0.017795\n",
       "B-tim    0.016927\n",
       "B-per    0.015312\n",
       "I-org    0.013937\n",
       "I-geo    0.005383\n",
       "I-tim    0.004247\n",
       "B-art    0.001376\n",
       "I-gpe    0.000837\n",
       "I-art    0.000748\n",
       "B-eve    0.000628\n",
       "I-eve    0.000508\n",
       "B-nat    0.000449\n",
       "I-nat    0.000239\n",
       "Name: tag, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df.tag.value_counts(normalize=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence length\n",
    "tdf = df.set_index('sentence_idx')\n",
    "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
    "df = tdf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorial variables\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['pos'] = le.fit_transform(df.pos)\n",
    "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
    "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
    "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
    "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>London</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx  next-next-pos next-next-word  next-pos      next-word  pos  \\\n",
       "0           1.0             18  demonstrators         9             of   18   \n",
       "1           1.0             33           have        18  demonstrators    9   \n",
       "2           1.0             32        marched        33           have   18   \n",
       "3           1.0              9        through        32        marched   33   \n",
       "4           1.0             16         London         9        through   32   \n",
       "\n",
       "   prev-pos  prev-prev-pos prev-prev-word      prev-word           word tag  \\\n",
       "0        39             40     __START2__     __START1__      Thousands   O   \n",
       "1        18             39     __START1__      Thousands             of   O   \n",
       "2         9             18      Thousands             of  demonstrators   O   \n",
       "3        18              9             of  demonstrators           have   O   \n",
       "4        33             18  demonstrators           have        marched   O   \n",
       "\n",
       "   length  \n",
       "0      48  \n",
       "1      48  \n",
       "2      48  \n",
       "3      48  \n",
       "4      48  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 50155\n",
      "test 16719\n"
     ]
    }
   ],
   "source": [
    "# splitting\n",
    "y = LabelEncoder().fit_transform(df.tag)\n",
    "\n",
    "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
    "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
    "print('train', df_train.shape[0])\n",
    "print('test', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some wrappers to work with word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "   \n",
    "class Word2VecWrapper(TransformerMixin):\n",
    "    def __init__(self, window=5,negative=5, size=100, iter=100, is_cbow=False, random_state=SEED):\n",
    "        self.window_ = window\n",
    "        self.negative_ = negative\n",
    "        self.size_ = size\n",
    "        self.iter_ = iter\n",
    "        self.is_cbow_ = is_cbow\n",
    "        self.w2v = None\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def get_size(self):\n",
    "        return self.size_\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        X: list of strings\n",
    "        \"\"\"\n",
    "        sentences_list = [x.split() for x in X]\n",
    "        self.w2v = Word2Vec(sentences_list, \n",
    "                            window=self.window_,\n",
    "                            negative=self.negative_, \n",
    "                            size=self.size_, \n",
    "                            iter=self.iter_,\n",
    "                            sg=not self.is_cbow_, seed=self.random_state)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def has(self, word):\n",
    "        return word in self.w2v\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X: a list of words\n",
    "        \"\"\"\n",
    "        if self.w2v is None:\n",
    "            raise Exception('model not fitted')\n",
    "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 s, sys: 401 ms, total: 29.4 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# here we exploit that word2vec is an unsupervised learning algorithm\n",
    "# so we can train it on the whole dataset (subject to discussion)\n",
    "\n",
    "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
    "\n",
    "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
    "w2v_cbow.fit(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.05887736725599869\n",
      "test 0.060439542712750365\n",
      "CPU times: user 85.2 ms, sys: 19 ms, total: 104 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 1 \n",
    "# random labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('enc', OneHotEncoder()),\n",
    "    ('est', DummyClassifier(random_state=SEED)),\n",
    "])\n",
    "\n",
    "model.fit(df_train[columns], y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.46639500282346874\n",
      "test 0.39660981421559566\n",
      "CPU times: user 2min 56s, sys: 9.55 s, total: 3min 5s\n",
      "Wall time: 12min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 2 \n",
    "# pos features + one hot encoding + logistic regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('enc', OneHotEncoder()),\n",
    "    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
    "                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
    "])\n",
    "\n",
    "model.fit(df_train[columns], y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9564419272624621\n",
      "test 0.8107188907410726\n",
      "CPU times: user 2min 21s, sys: 16 s, total: 2min 37s\n",
      "Wall time: 9min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 3\n",
    "# use word2vec cbow embedding + baseline 2 + svm\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "import scipy.sparse as sp\n",
    "\n",
    "embeding = w2v_cbow\n",
    "encoder_pos = OneHotEncoder()\n",
    "X_train = sp.hstack([\n",
    "    embeding.transform(df_train.word),\n",
    "    embeding.transform(df_train['next-word']),\n",
    "    embeding.transform(df_train['next-next-word']),\n",
    "    embeding.transform(df_train['prev-word']),\n",
    "    embeding.transform(df_train['prev-prev-word']),\n",
    "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
    "])\n",
    "X_test = sp.hstack([\n",
    "    embeding.transform(df_test.word),\n",
    "    embeding.transform(df_test['next-word']),\n",
    "    embeding.transform(df_test['next-next-word']),\n",
    "    embeding.transform(df_test['prev-word']),\n",
    "    embeding.transform(df_test['prev-prev-word']),\n",
    "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
    "])\n",
    "\n",
    "model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
    "                                    {'C': np.logspace(-4, 0, 5)}, \n",
    "                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos', 'sentence_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 311 ms, sys: 18.7 ms, total: 329 ms\n",
      "Wall time: 329 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=1337, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(df_train[columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9840905177482637\n",
      "test 0.7681646307933354\n"
     ]
    }
   ],
   "source": [
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=1000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 1.31 s, total: 30.9 s\n",
      "Wall time: 31.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=1337, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(df_train[columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9998132730662732\n",
      "test 0.8375171019038912\n"
     ]
    }
   ],
   "source": [
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline побит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "?CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(learning_rate=1, iterations=500, random_state=SEED, depth=10, loss_function='MultiClassOneVsAll', custom_loss='F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: -0.1520296\ttotal: 230ms\tremaining: 1m 54s\n",
      "1:\tlearn: -0.0711681\ttotal: 459ms\tremaining: 1m 54s\n",
      "2:\tlearn: -0.0425666\ttotal: 693ms\tremaining: 1m 54s\n",
      "3:\tlearn: -0.0331851\ttotal: 921ms\tremaining: 1m 54s\n",
      "4:\tlearn: -0.0283574\ttotal: 1.19s\tremaining: 1m 57s\n",
      "5:\tlearn: -0.0261516\ttotal: 1.42s\tremaining: 1m 56s\n",
      "6:\tlearn: -0.0249479\ttotal: 1.64s\tremaining: 1m 55s\n",
      "7:\tlearn: -0.0237545\ttotal: 1.87s\tremaining: 1m 55s\n",
      "8:\tlearn: -0.0229641\ttotal: 2.1s\tremaining: 1m 54s\n",
      "9:\tlearn: -0.0224826\ttotal: 2.32s\tremaining: 1m 53s\n",
      "10:\tlearn: -0.0216834\ttotal: 2.55s\tremaining: 1m 53s\n",
      "11:\tlearn: -0.0209366\ttotal: 2.79s\tremaining: 1m 53s\n",
      "12:\tlearn: -0.0204668\ttotal: 3.02s\tremaining: 1m 53s\n",
      "13:\tlearn: -0.0199539\ttotal: 3.25s\tremaining: 1m 52s\n",
      "14:\tlearn: -0.0195303\ttotal: 3.47s\tremaining: 1m 52s\n",
      "15:\tlearn: -0.0191501\ttotal: 3.7s\tremaining: 1m 52s\n",
      "16:\tlearn: -0.0188818\ttotal: 3.93s\tremaining: 1m 51s\n",
      "17:\tlearn: -0.0185861\ttotal: 4.15s\tremaining: 1m 51s\n",
      "18:\tlearn: -0.0182668\ttotal: 4.38s\tremaining: 1m 50s\n",
      "19:\tlearn: -0.0180081\ttotal: 4.63s\tremaining: 1m 51s\n",
      "20:\tlearn: -0.0177654\ttotal: 4.86s\tremaining: 1m 50s\n",
      "21:\tlearn: -0.0175282\ttotal: 5.09s\tremaining: 1m 50s\n",
      "22:\tlearn: -0.0172187\ttotal: 5.33s\tremaining: 1m 50s\n",
      "23:\tlearn: -0.0170148\ttotal: 5.56s\tremaining: 1m 50s\n",
      "24:\tlearn: -0.0167808\ttotal: 5.84s\tremaining: 1m 50s\n",
      "25:\tlearn: -0.0164168\ttotal: 6.11s\tremaining: 1m 51s\n",
      "26:\tlearn: -0.0161134\ttotal: 6.33s\tremaining: 1m 50s\n",
      "27:\tlearn: -0.0159214\ttotal: 6.58s\tremaining: 1m 50s\n",
      "28:\tlearn: -0.0157474\ttotal: 6.82s\tremaining: 1m 50s\n",
      "29:\tlearn: -0.0155630\ttotal: 7.04s\tremaining: 1m 50s\n",
      "30:\tlearn: -0.0152034\ttotal: 7.27s\tremaining: 1m 50s\n",
      "31:\tlearn: -0.0149921\ttotal: 7.5s\tremaining: 1m 49s\n",
      "32:\tlearn: -0.0148397\ttotal: 7.82s\tremaining: 1m 50s\n",
      "33:\tlearn: -0.0146706\ttotal: 8.04s\tremaining: 1m 50s\n",
      "34:\tlearn: -0.0144134\ttotal: 8.27s\tremaining: 1m 49s\n",
      "35:\tlearn: -0.0142342\ttotal: 8.49s\tremaining: 1m 49s\n",
      "36:\tlearn: -0.0141049\ttotal: 8.73s\tremaining: 1m 49s\n",
      "37:\tlearn: -0.0138784\ttotal: 8.96s\tremaining: 1m 48s\n",
      "38:\tlearn: -0.0136646\ttotal: 9.2s\tremaining: 1m 48s\n",
      "39:\tlearn: -0.0135246\ttotal: 9.54s\tremaining: 1m 49s\n",
      "40:\tlearn: -0.0133943\ttotal: 9.8s\tremaining: 1m 49s\n",
      "41:\tlearn: -0.0132593\ttotal: 10s\tremaining: 1m 49s\n",
      "42:\tlearn: -0.0130895\ttotal: 10.3s\tremaining: 1m 49s\n",
      "43:\tlearn: -0.0129718\ttotal: 10.5s\tremaining: 1m 49s\n",
      "44:\tlearn: -0.0128303\ttotal: 10.8s\tremaining: 1m 49s\n",
      "45:\tlearn: -0.0127200\ttotal: 11.1s\tremaining: 1m 49s\n",
      "46:\tlearn: -0.0125591\ttotal: 11.3s\tremaining: 1m 49s\n",
      "47:\tlearn: -0.0124150\ttotal: 11.6s\tremaining: 1m 49s\n",
      "48:\tlearn: -0.0122977\ttotal: 11.8s\tremaining: 1m 48s\n",
      "49:\tlearn: -0.0121796\ttotal: 12.1s\tremaining: 1m 48s\n",
      "50:\tlearn: -0.0120861\ttotal: 12.3s\tremaining: 1m 48s\n",
      "51:\tlearn: -0.0120191\ttotal: 12.6s\tremaining: 1m 48s\n",
      "52:\tlearn: -0.0119222\ttotal: 12.8s\tremaining: 1m 47s\n",
      "53:\tlearn: -0.0118005\ttotal: 13s\tremaining: 1m 47s\n",
      "54:\tlearn: -0.0116629\ttotal: 13.3s\tremaining: 1m 47s\n",
      "55:\tlearn: -0.0115532\ttotal: 13.5s\tremaining: 1m 47s\n",
      "56:\tlearn: -0.0113739\ttotal: 13.8s\tremaining: 1m 46s\n",
      "57:\tlearn: -0.0112623\ttotal: 14s\tremaining: 1m 46s\n",
      "58:\tlearn: -0.0111612\ttotal: 14.2s\tremaining: 1m 46s\n",
      "59:\tlearn: -0.0110547\ttotal: 14.5s\tremaining: 1m 46s\n",
      "60:\tlearn: -0.0109632\ttotal: 14.8s\tremaining: 1m 46s\n",
      "61:\tlearn: -0.0108906\ttotal: 15.1s\tremaining: 1m 46s\n",
      "62:\tlearn: -0.0108221\ttotal: 15.3s\tremaining: 1m 46s\n",
      "63:\tlearn: -0.0107425\ttotal: 15.5s\tremaining: 1m 45s\n",
      "64:\tlearn: -0.0106629\ttotal: 15.8s\tremaining: 1m 45s\n",
      "65:\tlearn: -0.0105967\ttotal: 16.1s\tremaining: 1m 45s\n",
      "66:\tlearn: -0.0104668\ttotal: 16.3s\tremaining: 1m 45s\n",
      "67:\tlearn: -0.0104116\ttotal: 16.5s\tremaining: 1m 44s\n",
      "68:\tlearn: -0.0102931\ttotal: 16.7s\tremaining: 1m 44s\n",
      "69:\tlearn: -0.0102196\ttotal: 17s\tremaining: 1m 44s\n",
      "70:\tlearn: -0.0100988\ttotal: 17.2s\tremaining: 1m 43s\n",
      "71:\tlearn: -0.0099912\ttotal: 17.4s\tremaining: 1m 43s\n",
      "72:\tlearn: -0.0099314\ttotal: 17.6s\tremaining: 1m 43s\n",
      "73:\tlearn: -0.0098190\ttotal: 17.9s\tremaining: 1m 43s\n",
      "74:\tlearn: -0.0097201\ttotal: 18.2s\tremaining: 1m 43s\n",
      "75:\tlearn: -0.0096613\ttotal: 18.5s\tremaining: 1m 42s\n",
      "76:\tlearn: -0.0095875\ttotal: 18.7s\tremaining: 1m 42s\n",
      "77:\tlearn: -0.0095403\ttotal: 18.9s\tremaining: 1m 42s\n",
      "78:\tlearn: -0.0094401\ttotal: 19.2s\tremaining: 1m 42s\n",
      "79:\tlearn: -0.0093907\ttotal: 19.4s\tremaining: 1m 41s\n",
      "80:\tlearn: -0.0093387\ttotal: 19.6s\tremaining: 1m 41s\n",
      "81:\tlearn: -0.0092912\ttotal: 19.9s\tremaining: 1m 41s\n",
      "82:\tlearn: -0.0092256\ttotal: 20.1s\tremaining: 1m 40s\n",
      "83:\tlearn: -0.0091387\ttotal: 20.3s\tremaining: 1m 40s\n",
      "84:\tlearn: -0.0090603\ttotal: 20.5s\tremaining: 1m 40s\n",
      "85:\tlearn: -0.0090193\ttotal: 20.8s\tremaining: 1m 39s\n",
      "86:\tlearn: -0.0089565\ttotal: 21s\tremaining: 1m 39s\n",
      "87:\tlearn: -0.0088543\ttotal: 21.2s\tremaining: 1m 39s\n",
      "88:\tlearn: -0.0087700\ttotal: 21.4s\tremaining: 1m 38s\n",
      "89:\tlearn: -0.0087029\ttotal: 21.7s\tremaining: 1m 38s\n",
      "90:\tlearn: -0.0085968\ttotal: 21.9s\tremaining: 1m 38s\n",
      "91:\tlearn: -0.0085209\ttotal: 22.1s\tremaining: 1m 38s\n",
      "92:\tlearn: -0.0084638\ttotal: 22.3s\tremaining: 1m 37s\n",
      "93:\tlearn: -0.0083900\ttotal: 22.5s\tremaining: 1m 37s\n",
      "94:\tlearn: -0.0083351\ttotal: 22.8s\tremaining: 1m 37s\n",
      "95:\tlearn: -0.0082838\ttotal: 23s\tremaining: 1m 36s\n",
      "96:\tlearn: -0.0082377\ttotal: 23.2s\tremaining: 1m 36s\n",
      "97:\tlearn: -0.0082140\ttotal: 23.4s\tremaining: 1m 36s\n",
      "98:\tlearn: -0.0081466\ttotal: 23.7s\tremaining: 1m 35s\n",
      "99:\tlearn: -0.0081002\ttotal: 23.9s\tremaining: 1m 35s\n",
      "100:\tlearn: -0.0080508\ttotal: 24.1s\tremaining: 1m 35s\n",
      "101:\tlearn: -0.0080030\ttotal: 24.3s\tremaining: 1m 34s\n",
      "102:\tlearn: -0.0079526\ttotal: 24.5s\tremaining: 1m 34s\n",
      "103:\tlearn: -0.0078924\ttotal: 24.8s\tremaining: 1m 34s\n",
      "104:\tlearn: -0.0078092\ttotal: 25s\tremaining: 1m 34s\n",
      "105:\tlearn: -0.0077653\ttotal: 25.2s\tremaining: 1m 33s\n",
      "106:\tlearn: -0.0077257\ttotal: 25.4s\tremaining: 1m 33s\n",
      "107:\tlearn: -0.0076570\ttotal: 25.7s\tremaining: 1m 33s\n",
      "108:\tlearn: -0.0076135\ttotal: 25.9s\tremaining: 1m 32s\n",
      "109:\tlearn: -0.0075838\ttotal: 26.1s\tremaining: 1m 32s\n",
      "110:\tlearn: -0.0075560\ttotal: 26.3s\tremaining: 1m 32s\n",
      "111:\tlearn: -0.0074989\ttotal: 26.5s\tremaining: 1m 31s\n",
      "112:\tlearn: -0.0074527\ttotal: 26.8s\tremaining: 1m 31s\n",
      "113:\tlearn: -0.0074178\ttotal: 27s\tremaining: 1m 31s\n",
      "114:\tlearn: -0.0073599\ttotal: 27.2s\tremaining: 1m 31s\n",
      "115:\tlearn: -0.0073272\ttotal: 27.4s\tremaining: 1m 30s\n",
      "116:\tlearn: -0.0072841\ttotal: 27.7s\tremaining: 1m 30s\n",
      "117:\tlearn: -0.0072336\ttotal: 27.9s\tremaining: 1m 30s\n",
      "118:\tlearn: -0.0072074\ttotal: 28.1s\tremaining: 1m 30s\n",
      "119:\tlearn: -0.0071746\ttotal: 28.3s\tremaining: 1m 29s\n",
      "120:\tlearn: -0.0071313\ttotal: 28.6s\tremaining: 1m 29s\n",
      "121:\tlearn: -0.0070816\ttotal: 28.8s\tremaining: 1m 29s\n",
      "122:\tlearn: -0.0070308\ttotal: 29s\tremaining: 1m 28s\n",
      "123:\tlearn: -0.0069923\ttotal: 29.2s\tremaining: 1m 28s\n",
      "124:\tlearn: -0.0069338\ttotal: 29.5s\tremaining: 1m 28s\n",
      "125:\tlearn: -0.0069037\ttotal: 29.7s\tremaining: 1m 28s\n",
      "126:\tlearn: -0.0068741\ttotal: 29.9s\tremaining: 1m 27s\n",
      "127:\tlearn: -0.0068169\ttotal: 30.1s\tremaining: 1m 27s\n",
      "128:\tlearn: -0.0067601\ttotal: 30.4s\tremaining: 1m 27s\n",
      "129:\tlearn: -0.0067013\ttotal: 30.6s\tremaining: 1m 27s\n",
      "130:\tlearn: -0.0066735\ttotal: 30.8s\tremaining: 1m 26s\n",
      "131:\tlearn: -0.0066214\ttotal: 31s\tremaining: 1m 26s\n",
      "132:\tlearn: -0.0065675\ttotal: 31.2s\tremaining: 1m 26s\n",
      "133:\tlearn: -0.0065322\ttotal: 31.5s\tremaining: 1m 25s\n",
      "134:\tlearn: -0.0065143\ttotal: 31.7s\tremaining: 1m 25s\n",
      "135:\tlearn: -0.0064933\ttotal: 31.9s\tremaining: 1m 25s\n",
      "136:\tlearn: -0.0064457\ttotal: 32.1s\tremaining: 1m 25s\n",
      "137:\tlearn: -0.0064072\ttotal: 32.4s\tremaining: 1m 24s\n",
      "138:\tlearn: -0.0063786\ttotal: 32.6s\tremaining: 1m 24s\n",
      "139:\tlearn: -0.0063320\ttotal: 32.8s\tremaining: 1m 24s\n",
      "140:\tlearn: -0.0063072\ttotal: 33s\tremaining: 1m 24s\n",
      "141:\tlearn: -0.0062761\ttotal: 33.3s\tremaining: 1m 23s\n",
      "142:\tlearn: -0.0062485\ttotal: 33.5s\tremaining: 1m 23s\n",
      "143:\tlearn: -0.0062169\ttotal: 33.7s\tremaining: 1m 23s\n",
      "144:\tlearn: -0.0061738\ttotal: 33.9s\tremaining: 1m 23s\n",
      "145:\tlearn: -0.0061432\ttotal: 34.2s\tremaining: 1m 22s\n",
      "146:\tlearn: -0.0061008\ttotal: 34.4s\tremaining: 1m 22s\n",
      "147:\tlearn: -0.0060823\ttotal: 34.6s\tremaining: 1m 22s\n",
      "148:\tlearn: -0.0060436\ttotal: 34.8s\tremaining: 1m 22s\n",
      "149:\tlearn: -0.0060003\ttotal: 35.1s\tremaining: 1m 21s\n",
      "150:\tlearn: -0.0059695\ttotal: 35.3s\tremaining: 1m 21s\n",
      "151:\tlearn: -0.0059478\ttotal: 35.5s\tremaining: 1m 21s\n",
      "152:\tlearn: -0.0059168\ttotal: 35.7s\tremaining: 1m 21s\n",
      "153:\tlearn: -0.0058815\ttotal: 36s\tremaining: 1m 20s\n",
      "154:\tlearn: -0.0058539\ttotal: 36.2s\tremaining: 1m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155:\tlearn: -0.0058288\ttotal: 36.4s\tremaining: 1m 20s\n",
      "156:\tlearn: -0.0058119\ttotal: 36.6s\tremaining: 1m 20s\n",
      "157:\tlearn: -0.0057891\ttotal: 36.8s\tremaining: 1m 19s\n",
      "158:\tlearn: -0.0057500\ttotal: 37.1s\tremaining: 1m 19s\n",
      "159:\tlearn: -0.0057181\ttotal: 37.3s\tremaining: 1m 19s\n",
      "160:\tlearn: -0.0056843\ttotal: 37.5s\tremaining: 1m 18s\n",
      "161:\tlearn: -0.0056526\ttotal: 37.7s\tremaining: 1m 18s\n",
      "162:\tlearn: -0.0056183\ttotal: 38s\tremaining: 1m 18s\n",
      "163:\tlearn: -0.0055753\ttotal: 38.2s\tremaining: 1m 18s\n",
      "164:\tlearn: -0.0055562\ttotal: 38.4s\tremaining: 1m 17s\n",
      "165:\tlearn: -0.0055375\ttotal: 38.6s\tremaining: 1m 17s\n",
      "166:\tlearn: -0.0055095\ttotal: 38.8s\tremaining: 1m 17s\n",
      "167:\tlearn: -0.0054661\ttotal: 39.1s\tremaining: 1m 17s\n",
      "168:\tlearn: -0.0054496\ttotal: 39.3s\tremaining: 1m 16s\n",
      "169:\tlearn: -0.0054290\ttotal: 39.5s\tremaining: 1m 16s\n",
      "170:\tlearn: -0.0054118\ttotal: 39.7s\tremaining: 1m 16s\n",
      "171:\tlearn: -0.0053891\ttotal: 39.9s\tremaining: 1m 16s\n",
      "172:\tlearn: -0.0053634\ttotal: 40.2s\tremaining: 1m 15s\n",
      "173:\tlearn: -0.0053304\ttotal: 40.4s\tremaining: 1m 15s\n",
      "174:\tlearn: -0.0052861\ttotal: 40.6s\tremaining: 1m 15s\n",
      "175:\tlearn: -0.0052540\ttotal: 40.8s\tremaining: 1m 15s\n",
      "176:\tlearn: -0.0052364\ttotal: 41.1s\tremaining: 1m 14s\n",
      "177:\tlearn: -0.0052093\ttotal: 41.3s\tremaining: 1m 14s\n",
      "178:\tlearn: -0.0051853\ttotal: 41.5s\tremaining: 1m 14s\n",
      "179:\tlearn: -0.0051591\ttotal: 41.7s\tremaining: 1m 14s\n",
      "180:\tlearn: -0.0051405\ttotal: 41.9s\tremaining: 1m 13s\n",
      "181:\tlearn: -0.0051146\ttotal: 42.2s\tremaining: 1m 13s\n",
      "182:\tlearn: -0.0050994\ttotal: 42.4s\tremaining: 1m 13s\n",
      "183:\tlearn: -0.0050779\ttotal: 42.6s\tremaining: 1m 13s\n",
      "184:\tlearn: -0.0050460\ttotal: 42.8s\tremaining: 1m 12s\n",
      "185:\tlearn: -0.0050138\ttotal: 43s\tremaining: 1m 12s\n",
      "186:\tlearn: -0.0049945\ttotal: 43.3s\tremaining: 1m 12s\n",
      "187:\tlearn: -0.0049635\ttotal: 43.5s\tremaining: 1m 12s\n",
      "188:\tlearn: -0.0049290\ttotal: 43.7s\tremaining: 1m 11s\n",
      "189:\tlearn: -0.0049026\ttotal: 43.9s\tremaining: 1m 11s\n",
      "190:\tlearn: -0.0048785\ttotal: 44.2s\tremaining: 1m 11s\n",
      "191:\tlearn: -0.0048640\ttotal: 44.4s\tremaining: 1m 11s\n",
      "192:\tlearn: -0.0048419\ttotal: 44.6s\tremaining: 1m 10s\n",
      "193:\tlearn: -0.0048219\ttotal: 44.8s\tremaining: 1m 10s\n",
      "194:\tlearn: -0.0048081\ttotal: 45s\tremaining: 1m 10s\n",
      "195:\tlearn: -0.0047916\ttotal: 45.3s\tremaining: 1m 10s\n",
      "196:\tlearn: -0.0047601\ttotal: 45.5s\tremaining: 1m 9s\n",
      "197:\tlearn: -0.0047453\ttotal: 45.7s\tremaining: 1m 9s\n",
      "198:\tlearn: -0.0047257\ttotal: 45.9s\tremaining: 1m 9s\n",
      "199:\tlearn: -0.0046944\ttotal: 46.1s\tremaining: 1m 9s\n",
      "200:\tlearn: -0.0046707\ttotal: 46.4s\tremaining: 1m 8s\n",
      "201:\tlearn: -0.0046583\ttotal: 46.6s\tremaining: 1m 8s\n",
      "202:\tlearn: -0.0046476\ttotal: 46.8s\tremaining: 1m 8s\n",
      "203:\tlearn: -0.0046310\ttotal: 47s\tremaining: 1m 8s\n",
      "204:\tlearn: -0.0046124\ttotal: 47.3s\tremaining: 1m 8s\n",
      "205:\tlearn: -0.0045879\ttotal: 47.5s\tremaining: 1m 7s\n",
      "206:\tlearn: -0.0045695\ttotal: 47.7s\tremaining: 1m 7s\n",
      "207:\tlearn: -0.0045482\ttotal: 47.9s\tremaining: 1m 7s\n",
      "208:\tlearn: -0.0045259\ttotal: 48.1s\tremaining: 1m 7s\n",
      "209:\tlearn: -0.0045059\ttotal: 48.4s\tremaining: 1m 6s\n",
      "210:\tlearn: -0.0044977\ttotal: 48.6s\tremaining: 1m 6s\n",
      "211:\tlearn: -0.0044770\ttotal: 48.8s\tremaining: 1m 6s\n",
      "212:\tlearn: -0.0044586\ttotal: 49s\tremaining: 1m 6s\n",
      "213:\tlearn: -0.0044354\ttotal: 49.2s\tremaining: 1m 5s\n",
      "214:\tlearn: -0.0044180\ttotal: 49.5s\tremaining: 1m 5s\n",
      "215:\tlearn: -0.0044016\ttotal: 49.7s\tremaining: 1m 5s\n",
      "216:\tlearn: -0.0043776\ttotal: 49.9s\tremaining: 1m 5s\n",
      "217:\tlearn: -0.0043579\ttotal: 50.1s\tremaining: 1m 4s\n",
      "218:\tlearn: -0.0043385\ttotal: 50.3s\tremaining: 1m 4s\n",
      "219:\tlearn: -0.0043179\ttotal: 50.6s\tremaining: 1m 4s\n",
      "220:\tlearn: -0.0043053\ttotal: 50.8s\tremaining: 1m 4s\n",
      "221:\tlearn: -0.0042887\ttotal: 51s\tremaining: 1m 3s\n",
      "222:\tlearn: -0.0042727\ttotal: 51.2s\tremaining: 1m 3s\n",
      "223:\tlearn: -0.0042607\ttotal: 51.5s\tremaining: 1m 3s\n",
      "224:\tlearn: -0.0042438\ttotal: 51.7s\tremaining: 1m 3s\n",
      "225:\tlearn: -0.0042228\ttotal: 51.9s\tremaining: 1m 2s\n",
      "226:\tlearn: -0.0042139\ttotal: 52.1s\tremaining: 1m 2s\n",
      "227:\tlearn: -0.0041902\ttotal: 52.3s\tremaining: 1m 2s\n",
      "228:\tlearn: -0.0041681\ttotal: 52.6s\tremaining: 1m 2s\n",
      "229:\tlearn: -0.0041596\ttotal: 52.8s\tremaining: 1m 1s\n",
      "230:\tlearn: -0.0041468\ttotal: 53s\tremaining: 1m 1s\n",
      "231:\tlearn: -0.0041254\ttotal: 53.2s\tremaining: 1m 1s\n",
      "232:\tlearn: -0.0041124\ttotal: 53.4s\tremaining: 1m 1s\n",
      "233:\tlearn: -0.0040952\ttotal: 53.7s\tremaining: 1m 1s\n",
      "234:\tlearn: -0.0040793\ttotal: 53.9s\tremaining: 1m\n",
      "235:\tlearn: -0.0040675\ttotal: 54.1s\tremaining: 1m\n",
      "236:\tlearn: -0.0040561\ttotal: 54.3s\tremaining: 1m\n",
      "237:\tlearn: -0.0040447\ttotal: 54.5s\tremaining: 1m\n",
      "238:\tlearn: -0.0040252\ttotal: 54.8s\tremaining: 59.8s\n",
      "239:\tlearn: -0.0040109\ttotal: 55s\tremaining: 59.6s\n",
      "240:\tlearn: -0.0040019\ttotal: 55.2s\tremaining: 59.3s\n",
      "241:\tlearn: -0.0039816\ttotal: 55.4s\tremaining: 59.1s\n",
      "242:\tlearn: -0.0039629\ttotal: 55.6s\tremaining: 58.9s\n",
      "243:\tlearn: -0.0039535\ttotal: 55.9s\tremaining: 58.6s\n",
      "244:\tlearn: -0.0039392\ttotal: 56.1s\tremaining: 58.4s\n",
      "245:\tlearn: -0.0039279\ttotal: 56.3s\tremaining: 58.1s\n",
      "246:\tlearn: -0.0039138\ttotal: 56.5s\tremaining: 57.9s\n",
      "247:\tlearn: -0.0038972\ttotal: 56.7s\tremaining: 57.7s\n",
      "248:\tlearn: -0.0038842\ttotal: 57s\tremaining: 57.4s\n",
      "249:\tlearn: -0.0038611\ttotal: 57.2s\tremaining: 57.2s\n",
      "250:\tlearn: -0.0038477\ttotal: 57.4s\tremaining: 56.9s\n",
      "251:\tlearn: -0.0038365\ttotal: 57.6s\tremaining: 56.7s\n",
      "252:\tlearn: -0.0038257\ttotal: 57.8s\tremaining: 56.5s\n",
      "253:\tlearn: -0.0038106\ttotal: 58.1s\tremaining: 56.2s\n",
      "254:\tlearn: -0.0037977\ttotal: 58.3s\tremaining: 56s\n",
      "255:\tlearn: -0.0037778\ttotal: 58.5s\tremaining: 55.8s\n",
      "256:\tlearn: -0.0037569\ttotal: 58.7s\tremaining: 55.5s\n",
      "257:\tlearn: -0.0037495\ttotal: 58.9s\tremaining: 55.3s\n",
      "258:\tlearn: -0.0037389\ttotal: 59.2s\tremaining: 55.1s\n",
      "259:\tlearn: -0.0037310\ttotal: 59.4s\tremaining: 54.8s\n",
      "260:\tlearn: -0.0037102\ttotal: 59.6s\tremaining: 54.6s\n",
      "261:\tlearn: -0.0037030\ttotal: 59.8s\tremaining: 54.3s\n",
      "262:\tlearn: -0.0036877\ttotal: 1m\tremaining: 54.1s\n",
      "263:\tlearn: -0.0036686\ttotal: 1m\tremaining: 53.9s\n",
      "264:\tlearn: -0.0036528\ttotal: 1m\tremaining: 53.6s\n",
      "265:\tlearn: -0.0036347\ttotal: 1m\tremaining: 53.4s\n",
      "266:\tlearn: -0.0036233\ttotal: 1m\tremaining: 53.2s\n",
      "267:\tlearn: -0.0036152\ttotal: 1m 1s\tremaining: 52.9s\n",
      "268:\tlearn: -0.0036037\ttotal: 1m 1s\tremaining: 52.7s\n",
      "269:\tlearn: -0.0035900\ttotal: 1m 1s\tremaining: 52.5s\n",
      "270:\tlearn: -0.0035801\ttotal: 1m 1s\tremaining: 52.2s\n",
      "271:\tlearn: -0.0035695\ttotal: 1m 2s\tremaining: 52s\n",
      "272:\tlearn: -0.0035579\ttotal: 1m 2s\tremaining: 51.8s\n",
      "273:\tlearn: -0.0035456\ttotal: 1m 2s\tremaining: 51.5s\n",
      "274:\tlearn: -0.0035293\ttotal: 1m 2s\tremaining: 51.3s\n",
      "275:\tlearn: -0.0035176\ttotal: 1m 2s\tremaining: 51.1s\n",
      "276:\tlearn: -0.0035066\ttotal: 1m 3s\tremaining: 50.8s\n",
      "277:\tlearn: -0.0034954\ttotal: 1m 3s\tremaining: 50.6s\n",
      "278:\tlearn: -0.0034824\ttotal: 1m 3s\tremaining: 50.4s\n",
      "279:\tlearn: -0.0034727\ttotal: 1m 3s\tremaining: 50.1s\n",
      "280:\tlearn: -0.0034652\ttotal: 1m 4s\tremaining: 49.9s\n",
      "281:\tlearn: -0.0034553\ttotal: 1m 4s\tremaining: 49.6s\n",
      "282:\tlearn: -0.0034415\ttotal: 1m 4s\tremaining: 49.4s\n",
      "283:\tlearn: -0.0034224\ttotal: 1m 4s\tremaining: 49.2s\n",
      "284:\tlearn: -0.0034103\ttotal: 1m 4s\tremaining: 48.9s\n",
      "285:\tlearn: -0.0033948\ttotal: 1m 5s\tremaining: 48.7s\n",
      "286:\tlearn: -0.0033810\ttotal: 1m 5s\tremaining: 48.5s\n",
      "287:\tlearn: -0.0033710\ttotal: 1m 5s\tremaining: 48.2s\n",
      "288:\tlearn: -0.0033607\ttotal: 1m 5s\tremaining: 48s\n",
      "289:\tlearn: -0.0033496\ttotal: 1m 5s\tremaining: 47.8s\n",
      "290:\tlearn: -0.0033362\ttotal: 1m 6s\tremaining: 47.5s\n",
      "291:\tlearn: -0.0033291\ttotal: 1m 6s\tremaining: 47.3s\n",
      "292:\tlearn: -0.0033214\ttotal: 1m 6s\tremaining: 47.1s\n",
      "293:\tlearn: -0.0033125\ttotal: 1m 6s\tremaining: 46.8s\n",
      "294:\tlearn: -0.0033001\ttotal: 1m 7s\tremaining: 46.6s\n",
      "295:\tlearn: -0.0032926\ttotal: 1m 7s\tremaining: 46.4s\n",
      "296:\tlearn: -0.0032824\ttotal: 1m 7s\tremaining: 46.1s\n",
      "297:\tlearn: -0.0032699\ttotal: 1m 7s\tremaining: 45.9s\n",
      "298:\tlearn: -0.0032613\ttotal: 1m 7s\tremaining: 45.7s\n",
      "299:\tlearn: -0.0032523\ttotal: 1m 8s\tremaining: 45.4s\n",
      "300:\tlearn: -0.0032393\ttotal: 1m 8s\tremaining: 45.2s\n",
      "301:\tlearn: -0.0032305\ttotal: 1m 8s\tremaining: 45s\n",
      "302:\tlearn: -0.0032229\ttotal: 1m 8s\tremaining: 44.8s\n",
      "303:\tlearn: -0.0032171\ttotal: 1m 9s\tremaining: 44.5s\n",
      "304:\tlearn: -0.0032051\ttotal: 1m 9s\tremaining: 44.3s\n",
      "305:\tlearn: -0.0031978\ttotal: 1m 9s\tremaining: 44.1s\n",
      "306:\tlearn: -0.0031907\ttotal: 1m 9s\tremaining: 43.8s\n",
      "307:\tlearn: -0.0031792\ttotal: 1m 9s\tremaining: 43.6s\n",
      "308:\tlearn: -0.0031731\ttotal: 1m 10s\tremaining: 43.4s\n",
      "309:\tlearn: -0.0031617\ttotal: 1m 10s\tremaining: 43.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310:\tlearn: -0.0031554\ttotal: 1m 10s\tremaining: 42.9s\n",
      "311:\tlearn: -0.0031504\ttotal: 1m 10s\tremaining: 42.7s\n",
      "312:\tlearn: -0.0031393\ttotal: 1m 11s\tremaining: 42.5s\n",
      "313:\tlearn: -0.0031322\ttotal: 1m 11s\tremaining: 42.2s\n",
      "314:\tlearn: -0.0031194\ttotal: 1m 11s\tremaining: 42s\n",
      "315:\tlearn: -0.0031129\ttotal: 1m 11s\tremaining: 41.8s\n",
      "316:\tlearn: -0.0031047\ttotal: 1m 11s\tremaining: 41.5s\n",
      "317:\tlearn: -0.0030978\ttotal: 1m 12s\tremaining: 41.3s\n",
      "318:\tlearn: -0.0030855\ttotal: 1m 12s\tremaining: 41.1s\n",
      "319:\tlearn: -0.0030742\ttotal: 1m 12s\tremaining: 40.8s\n",
      "320:\tlearn: -0.0030626\ttotal: 1m 12s\tremaining: 40.6s\n",
      "321:\tlearn: -0.0030539\ttotal: 1m 13s\tremaining: 40.4s\n",
      "322:\tlearn: -0.0030390\ttotal: 1m 13s\tremaining: 40.1s\n",
      "323:\tlearn: -0.0030329\ttotal: 1m 13s\tremaining: 39.9s\n",
      "324:\tlearn: -0.0030206\ttotal: 1m 13s\tremaining: 39.7s\n",
      "325:\tlearn: -0.0030128\ttotal: 1m 13s\tremaining: 39.5s\n",
      "326:\tlearn: -0.0030007\ttotal: 1m 14s\tremaining: 39.2s\n",
      "327:\tlearn: -0.0029938\ttotal: 1m 14s\tremaining: 39s\n",
      "328:\tlearn: -0.0029880\ttotal: 1m 14s\tremaining: 38.8s\n",
      "329:\tlearn: -0.0029811\ttotal: 1m 14s\tremaining: 38.5s\n",
      "330:\tlearn: -0.0029700\ttotal: 1m 15s\tremaining: 38.3s\n",
      "331:\tlearn: -0.0029614\ttotal: 1m 15s\tremaining: 38.1s\n",
      "332:\tlearn: -0.0029551\ttotal: 1m 15s\tremaining: 37.8s\n",
      "333:\tlearn: -0.0029483\ttotal: 1m 15s\tremaining: 37.6s\n",
      "334:\tlearn: -0.0029409\ttotal: 1m 15s\tremaining: 37.4s\n",
      "335:\tlearn: -0.0029351\ttotal: 1m 16s\tremaining: 37.1s\n",
      "336:\tlearn: -0.0029238\ttotal: 1m 16s\tremaining: 36.9s\n",
      "337:\tlearn: -0.0029205\ttotal: 1m 16s\tremaining: 36.7s\n",
      "338:\tlearn: -0.0029104\ttotal: 1m 16s\tremaining: 36.5s\n",
      "339:\tlearn: -0.0029020\ttotal: 1m 16s\tremaining: 36.2s\n",
      "340:\tlearn: -0.0028958\ttotal: 1m 17s\tremaining: 36s\n",
      "341:\tlearn: -0.0028865\ttotal: 1m 17s\tremaining: 35.8s\n",
      "342:\tlearn: -0.0028783\ttotal: 1m 17s\tremaining: 35.5s\n",
      "343:\tlearn: -0.0028707\ttotal: 1m 17s\tremaining: 35.3s\n",
      "344:\tlearn: -0.0028624\ttotal: 1m 18s\tremaining: 35.1s\n",
      "345:\tlearn: -0.0028548\ttotal: 1m 18s\tremaining: 34.8s\n",
      "346:\tlearn: -0.0028430\ttotal: 1m 18s\tremaining: 34.6s\n",
      "347:\tlearn: -0.0028323\ttotal: 1m 18s\tremaining: 34.4s\n",
      "348:\tlearn: -0.0028251\ttotal: 1m 18s\tremaining: 34.2s\n",
      "349:\tlearn: -0.0028199\ttotal: 1m 19s\tremaining: 33.9s\n",
      "350:\tlearn: -0.0028116\ttotal: 1m 19s\tremaining: 33.7s\n",
      "351:\tlearn: -0.0028027\ttotal: 1m 19s\tremaining: 33.5s\n",
      "352:\tlearn: -0.0027896\ttotal: 1m 19s\tremaining: 33.2s\n",
      "353:\tlearn: -0.0027798\ttotal: 1m 20s\tremaining: 33s\n",
      "354:\tlearn: -0.0027718\ttotal: 1m 20s\tremaining: 32.8s\n",
      "355:\tlearn: -0.0027670\ttotal: 1m 20s\tremaining: 32.6s\n",
      "356:\tlearn: -0.0027588\ttotal: 1m 20s\tremaining: 32.3s\n",
      "357:\tlearn: -0.0027522\ttotal: 1m 20s\tremaining: 32.1s\n",
      "358:\tlearn: -0.0027464\ttotal: 1m 21s\tremaining: 31.9s\n",
      "359:\tlearn: -0.0027394\ttotal: 1m 21s\tremaining: 31.6s\n",
      "360:\tlearn: -0.0027319\ttotal: 1m 21s\tremaining: 31.4s\n",
      "361:\tlearn: -0.0027263\ttotal: 1m 21s\tremaining: 31.2s\n",
      "362:\tlearn: -0.0027141\ttotal: 1m 22s\tremaining: 31s\n",
      "363:\tlearn: -0.0027039\ttotal: 1m 22s\tremaining: 30.7s\n",
      "364:\tlearn: -0.0026912\ttotal: 1m 22s\tremaining: 30.5s\n",
      "365:\tlearn: -0.0026827\ttotal: 1m 22s\tremaining: 30.3s\n",
      "366:\tlearn: -0.0026755\ttotal: 1m 22s\tremaining: 30s\n",
      "367:\tlearn: -0.0026705\ttotal: 1m 23s\tremaining: 29.8s\n",
      "368:\tlearn: -0.0026613\ttotal: 1m 23s\tremaining: 29.6s\n",
      "369:\tlearn: -0.0026542\ttotal: 1m 23s\tremaining: 29.4s\n",
      "370:\tlearn: -0.0026497\ttotal: 1m 23s\tremaining: 29.1s\n",
      "371:\tlearn: -0.0026446\ttotal: 1m 24s\tremaining: 28.9s\n",
      "372:\tlearn: -0.0026368\ttotal: 1m 24s\tremaining: 28.7s\n",
      "373:\tlearn: -0.0026308\ttotal: 1m 24s\tremaining: 28.4s\n",
      "374:\tlearn: -0.0026245\ttotal: 1m 24s\tremaining: 28.2s\n",
      "375:\tlearn: -0.0026149\ttotal: 1m 24s\tremaining: 28s\n",
      "376:\tlearn: -0.0026109\ttotal: 1m 25s\tremaining: 27.8s\n",
      "377:\tlearn: -0.0026049\ttotal: 1m 25s\tremaining: 27.5s\n",
      "378:\tlearn: -0.0025992\ttotal: 1m 25s\tremaining: 27.3s\n",
      "379:\tlearn: -0.0025930\ttotal: 1m 25s\tremaining: 27.1s\n",
      "380:\tlearn: -0.0025900\ttotal: 1m 25s\tremaining: 26.9s\n",
      "381:\tlearn: -0.0025844\ttotal: 1m 26s\tremaining: 26.6s\n",
      "382:\tlearn: -0.0025774\ttotal: 1m 26s\tremaining: 26.4s\n",
      "383:\tlearn: -0.0025691\ttotal: 1m 26s\tremaining: 26.2s\n",
      "384:\tlearn: -0.0025625\ttotal: 1m 26s\tremaining: 25.9s\n",
      "385:\tlearn: -0.0025538\ttotal: 1m 27s\tremaining: 25.7s\n",
      "386:\tlearn: -0.0025478\ttotal: 1m 27s\tremaining: 25.5s\n",
      "387:\tlearn: -0.0025423\ttotal: 1m 27s\tremaining: 25.3s\n",
      "388:\tlearn: -0.0025367\ttotal: 1m 27s\tremaining: 25s\n",
      "389:\tlearn: -0.0025301\ttotal: 1m 27s\tremaining: 24.8s\n",
      "390:\tlearn: -0.0025243\ttotal: 1m 28s\tremaining: 24.6s\n",
      "391:\tlearn: -0.0025191\ttotal: 1m 28s\tremaining: 24.4s\n",
      "392:\tlearn: -0.0025124\ttotal: 1m 28s\tremaining: 24.1s\n",
      "393:\tlearn: -0.0025078\ttotal: 1m 28s\tremaining: 23.9s\n",
      "394:\tlearn: -0.0025019\ttotal: 1m 29s\tremaining: 23.7s\n",
      "395:\tlearn: -0.0024963\ttotal: 1m 29s\tremaining: 23.4s\n",
      "396:\tlearn: -0.0024918\ttotal: 1m 29s\tremaining: 23.2s\n",
      "397:\tlearn: -0.0024833\ttotal: 1m 29s\tremaining: 23s\n",
      "398:\tlearn: -0.0024779\ttotal: 1m 29s\tremaining: 22.8s\n",
      "399:\tlearn: -0.0024731\ttotal: 1m 30s\tremaining: 22.5s\n",
      "400:\tlearn: -0.0024673\ttotal: 1m 30s\tremaining: 22.3s\n",
      "401:\tlearn: -0.0024616\ttotal: 1m 30s\tremaining: 22.1s\n",
      "402:\tlearn: -0.0024554\ttotal: 1m 30s\tremaining: 21.9s\n",
      "403:\tlearn: -0.0024497\ttotal: 1m 31s\tremaining: 21.6s\n",
      "404:\tlearn: -0.0024451\ttotal: 1m 31s\tremaining: 21.4s\n",
      "405:\tlearn: -0.0024378\ttotal: 1m 31s\tremaining: 21.2s\n",
      "406:\tlearn: -0.0024315\ttotal: 1m 31s\tremaining: 20.9s\n",
      "407:\tlearn: -0.0024223\ttotal: 1m 31s\tremaining: 20.7s\n",
      "408:\tlearn: -0.0024169\ttotal: 1m 32s\tremaining: 20.5s\n",
      "409:\tlearn: -0.0024123\ttotal: 1m 32s\tremaining: 20.3s\n",
      "410:\tlearn: -0.0024052\ttotal: 1m 32s\tremaining: 20s\n",
      "411:\tlearn: -0.0023997\ttotal: 1m 32s\tremaining: 19.8s\n",
      "412:\tlearn: -0.0023910\ttotal: 1m 32s\tremaining: 19.6s\n",
      "413:\tlearn: -0.0023864\ttotal: 1m 33s\tremaining: 19.4s\n",
      "414:\tlearn: -0.0023830\ttotal: 1m 33s\tremaining: 19.1s\n",
      "415:\tlearn: -0.0023718\ttotal: 1m 33s\tremaining: 18.9s\n",
      "416:\tlearn: -0.0023672\ttotal: 1m 33s\tremaining: 18.7s\n",
      "417:\tlearn: -0.0023618\ttotal: 1m 34s\tremaining: 18.5s\n",
      "418:\tlearn: -0.0023579\ttotal: 1m 34s\tremaining: 18.3s\n",
      "419:\tlearn: -0.0023520\ttotal: 1m 34s\tremaining: 18s\n",
      "420:\tlearn: -0.0023431\ttotal: 1m 34s\tremaining: 17.8s\n",
      "421:\tlearn: -0.0023375\ttotal: 1m 35s\tremaining: 17.6s\n",
      "422:\tlearn: -0.0023342\ttotal: 1m 35s\tremaining: 17.4s\n",
      "423:\tlearn: -0.0023294\ttotal: 1m 35s\tremaining: 17.2s\n",
      "424:\tlearn: -0.0023263\ttotal: 1m 35s\tremaining: 16.9s\n",
      "425:\tlearn: -0.0023227\ttotal: 1m 36s\tremaining: 16.7s\n",
      "426:\tlearn: -0.0023185\ttotal: 1m 36s\tremaining: 16.5s\n",
      "427:\tlearn: -0.0023126\ttotal: 1m 36s\tremaining: 16.3s\n",
      "428:\tlearn: -0.0023055\ttotal: 1m 36s\tremaining: 16s\n",
      "429:\tlearn: -0.0023023\ttotal: 1m 37s\tremaining: 15.8s\n",
      "430:\tlearn: -0.0022967\ttotal: 1m 37s\tremaining: 15.6s\n",
      "431:\tlearn: -0.0022931\ttotal: 1m 37s\tremaining: 15.4s\n",
      "432:\tlearn: -0.0022849\ttotal: 1m 37s\tremaining: 15.1s\n",
      "433:\tlearn: -0.0022742\ttotal: 1m 38s\tremaining: 14.9s\n",
      "434:\tlearn: -0.0022694\ttotal: 1m 38s\tremaining: 14.7s\n",
      "435:\tlearn: -0.0022656\ttotal: 1m 38s\tremaining: 14.5s\n",
      "436:\tlearn: -0.0022596\ttotal: 1m 38s\tremaining: 14.3s\n",
      "437:\tlearn: -0.0022552\ttotal: 1m 39s\tremaining: 14s\n",
      "438:\tlearn: -0.0022486\ttotal: 1m 39s\tremaining: 13.8s\n",
      "439:\tlearn: -0.0022448\ttotal: 1m 39s\tremaining: 13.6s\n",
      "440:\tlearn: -0.0022392\ttotal: 1m 39s\tremaining: 13.4s\n",
      "441:\tlearn: -0.0022334\ttotal: 1m 40s\tremaining: 13.1s\n",
      "442:\tlearn: -0.0022287\ttotal: 1m 40s\tremaining: 12.9s\n",
      "443:\tlearn: -0.0022240\ttotal: 1m 40s\tremaining: 12.7s\n",
      "444:\tlearn: -0.0022186\ttotal: 1m 41s\tremaining: 12.5s\n",
      "445:\tlearn: -0.0022144\ttotal: 1m 41s\tremaining: 12.3s\n",
      "446:\tlearn: -0.0022117\ttotal: 1m 41s\tremaining: 12s\n",
      "447:\tlearn: -0.0022076\ttotal: 1m 41s\tremaining: 11.8s\n",
      "448:\tlearn: -0.0022034\ttotal: 1m 42s\tremaining: 11.6s\n",
      "449:\tlearn: -0.0021993\ttotal: 1m 42s\tremaining: 11.4s\n",
      "450:\tlearn: -0.0021953\ttotal: 1m 42s\tremaining: 11.2s\n",
      "451:\tlearn: -0.0021900\ttotal: 1m 42s\tremaining: 10.9s\n",
      "452:\tlearn: -0.0021848\ttotal: 1m 43s\tremaining: 10.7s\n",
      "453:\tlearn: -0.0021796\ttotal: 1m 43s\tremaining: 10.5s\n",
      "454:\tlearn: -0.0021755\ttotal: 1m 43s\tremaining: 10.3s\n",
      "455:\tlearn: -0.0021701\ttotal: 1m 43s\tremaining: 10s\n",
      "456:\tlearn: -0.0021635\ttotal: 1m 44s\tremaining: 9.81s\n",
      "457:\tlearn: -0.0021595\ttotal: 1m 44s\tremaining: 9.58s\n",
      "458:\tlearn: -0.0021558\ttotal: 1m 44s\tremaining: 9.36s\n",
      "459:\tlearn: -0.0021531\ttotal: 1m 44s\tremaining: 9.13s\n",
      "460:\tlearn: -0.0021491\ttotal: 1m 45s\tremaining: 8.9s\n",
      "461:\tlearn: -0.0021462\ttotal: 1m 45s\tremaining: 8.67s\n",
      "462:\tlearn: -0.0021401\ttotal: 1m 45s\tremaining: 8.44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463:\tlearn: -0.0021347\ttotal: 1m 45s\tremaining: 8.22s\n",
      "464:\tlearn: -0.0021325\ttotal: 1m 46s\tremaining: 7.99s\n",
      "465:\tlearn: -0.0021269\ttotal: 1m 46s\tremaining: 7.76s\n",
      "466:\tlearn: -0.0021238\ttotal: 1m 46s\tremaining: 7.53s\n",
      "467:\tlearn: -0.0021207\ttotal: 1m 46s\tremaining: 7.3s\n",
      "468:\tlearn: -0.0021172\ttotal: 1m 47s\tremaining: 7.07s\n",
      "469:\tlearn: -0.0021140\ttotal: 1m 47s\tremaining: 6.84s\n",
      "470:\tlearn: -0.0021105\ttotal: 1m 47s\tremaining: 6.61s\n",
      "471:\tlearn: -0.0021086\ttotal: 1m 47s\tremaining: 6.39s\n",
      "472:\tlearn: -0.0021035\ttotal: 1m 47s\tremaining: 6.16s\n",
      "473:\tlearn: -0.0020975\ttotal: 1m 48s\tremaining: 5.93s\n",
      "474:\tlearn: -0.0020936\ttotal: 1m 48s\tremaining: 5.7s\n",
      "475:\tlearn: -0.0020893\ttotal: 1m 48s\tremaining: 5.47s\n",
      "476:\tlearn: -0.0020839\ttotal: 1m 48s\tremaining: 5.24s\n",
      "477:\tlearn: -0.0020788\ttotal: 1m 48s\tremaining: 5.01s\n",
      "478:\tlearn: -0.0020714\ttotal: 1m 49s\tremaining: 4.79s\n",
      "479:\tlearn: -0.0020670\ttotal: 1m 49s\tremaining: 4.56s\n",
      "480:\tlearn: -0.0020615\ttotal: 1m 49s\tremaining: 4.33s\n",
      "481:\tlearn: -0.0020561\ttotal: 1m 49s\tremaining: 4.1s\n",
      "482:\tlearn: -0.0020522\ttotal: 1m 50s\tremaining: 3.87s\n",
      "483:\tlearn: -0.0020473\ttotal: 1m 50s\tremaining: 3.65s\n",
      "484:\tlearn: -0.0020450\ttotal: 1m 50s\tremaining: 3.42s\n",
      "485:\tlearn: -0.0020403\ttotal: 1m 50s\tremaining: 3.19s\n",
      "486:\tlearn: -0.0020368\ttotal: 1m 50s\tremaining: 2.96s\n",
      "487:\tlearn: -0.0020333\ttotal: 1m 51s\tremaining: 2.73s\n",
      "488:\tlearn: -0.0020286\ttotal: 1m 51s\tremaining: 2.5s\n",
      "489:\tlearn: -0.0020236\ttotal: 1m 51s\tremaining: 2.28s\n",
      "490:\tlearn: -0.0020210\ttotal: 1m 51s\tremaining: 2.05s\n",
      "491:\tlearn: -0.0020181\ttotal: 1m 52s\tremaining: 1.82s\n",
      "492:\tlearn: -0.0020142\ttotal: 1m 52s\tremaining: 1.59s\n",
      "493:\tlearn: -0.0020101\ttotal: 1m 52s\tremaining: 1.37s\n",
      "494:\tlearn: -0.0020059\ttotal: 1m 52s\tremaining: 1.14s\n",
      "495:\tlearn: -0.0020015\ttotal: 1m 53s\tremaining: 913ms\n",
      "496:\tlearn: -0.0019984\ttotal: 1m 53s\tremaining: 685ms\n",
      "497:\tlearn: -0.0019962\ttotal: 1m 53s\tremaining: 457ms\n",
      "498:\tlearn: -0.0019923\ttotal: 1m 53s\tremaining: 228ms\n",
      "499:\tlearn: -0.0019876\ttotal: 1m 54s\tremaining: 0us\n",
      "CPU times: user 3min 14s, sys: 1min, total: 4min 15s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x11584b550>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(df_train[columns], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9927836303142821\n",
      "test 0.8391754656989064\n"
     ]
    }
   ],
   "source": [
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline побит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why we selected f1 score with macro averaging as our classification quality measure? What other metrics are suitable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потому что наши классы несбалансированны.\n",
    "Можем также использовать метрику roc_auc_score с average='macro'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
